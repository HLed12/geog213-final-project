{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ebd826e-ee04-4d69-9d53-944590bfd4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import dask_geopandas as dg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acc06b0-5ce4-494d-b18a-e67c514dcb82",
   "metadata": {},
   "source": [
    "## Purpose of Notebook:\n",
    "This notebook shows how to download only part of a datset, how to download a different dataset from source.coop (using S3) and gives advice on users wishing to use the same dataset but for a different location (that are also only partially downloading the dataset).\n",
    "\n",
    "To download only some of the geoparquets in a dataset, you utilize the \"..._specified()\" functions in the utils.py.\n",
    "\n",
    "If you are capable/prefer to install all of a dataset's geoparquet files, feel free to follow the approach in 'worcester_analysis.ipynb'. But note, if you are not savvy with source.coop datasets, this notebook details how to alter the code to download a different dataset from the website. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d94024a-bada-483c-a102-1c89b327d699",
   "metadata": {},
   "source": [
    "### ATTENTION:\n",
    "User must follow below instructions and replace the AWS access key and secret access key. This is crucial for the analysis to work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7332e0fe-0dc2-4495-90f3-1bc172006b40",
   "metadata": {},
   "source": [
    "##### Utilizing data from: https://source.coop/repositories/wherobots/usa-structures/description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b0bb02-eecc-47c2-9759-583f67c57341",
   "metadata": {},
   "source": [
    "All data on Source Cooperative, are hosted on AWS S3 bucket. In order to access them, you need credentials that you can generate on Source Cooperative website. Atfer logging in, click on your name at the top right corner, and then click on your username. Then navigate to \"Manage\" page on the left side. At the bottom of this page you will find a section called \"API Keys\". If no key has been generated before, generate a new one and then copy the values for each of the following keys, and paste them in the following cell.\n",
    "\n",
    "source.coop website: https://source.coop/\n",
    "\n",
    "###### Source: https://github.com/github.com/HamedAlemo/vector-data-tutorial/scalable_vector_analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c8836e8-2b18-4e9e-b27b-de29fde29f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "#   Read Above 'ATTENTION' Note  #\n",
    "##################################\n",
    "\n",
    "AWS_ACCESS_KEY_ID = \"<YOUR ACCESS KEY>\"\n",
    "AWS_SECRET_ACCESS_KEY = \"<YOUR SECRET ACCESS KEY>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4ff4cad-0828-4441-ae6c-a97e642e141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3_client = boto3.client('s3',\n",
    "                         aws_access_key_id = AWS_ACCESS_KEY_ID, \n",
    "                         aws_secret_access_key = AWS_SECRET_ACCESS_KEY,\n",
    "                         endpoint_url='https://data.source.coop'\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "299f6bda-b00f-4ef0-8e4c-4477a3ccad88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:8787/status\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561e1f82-dd29-4a21-acff-a5033ba562af",
   "metadata": {},
   "source": [
    "Local path for downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "892320b2-8e2c-499a-8a46-8d480727f016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running from analysis file within the 'saved'//mounted folder and do NOT wish to save the raw data - delete the\n",
    "# first local_path and uncomment (remove #) on the second one\n",
    "\n",
    "local_path = \"./data/\" # saves data to machine\n",
    "# local_path =\"/data/\" # deletes data after removing the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "202556a2-ad5c-4c69-b9e0-d025708a8b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as ut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be36983-48b5-44e5-9b30-af1efb6268b7",
   "metadata": {},
   "source": [
    "##### This approach requires a list of parquet links to be inputted. However, if you desire to only download 1 of the parquet files, you can use the following example as a way to insert only 1 files later on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c291d56-2efc-4d78-bf07-4ad98e04db81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['parquet1.parquet']\n",
      "['parquet3.parquet']\n",
      "\n",
      "\n",
      "Once you get to the section for manually inputting the parquet links you want, you can do the same index operations to achieve just 1 parquet.\n"
     ]
    }
   ],
   "source": [
    "example_list_of_parquets = ['parquet1.parquet',\n",
    "                    'parquet2.parquet',\n",
    "                    'parquet3.parquet',\n",
    "                    'parquet4.parquet',\n",
    "                    'parquet5.parquet']\n",
    "\n",
    "print(example_list_of_parquets[0:1]) # returns the first index of the list (0)    Indices start at 0 in Python. Hence the '(0)'.\n",
    "\n",
    "print(example_list_of_parquets[2:3]) # returns the third index of the list (2)\n",
    "\n",
    "print('\\n\\nOnce you get to the section for manually inputting the parquet links you want, you can do the same index operations to achieve just 1 parquet.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2b9d38-cfd9-472f-aea8-93b10872ea9b",
   "metadata": {},
   "source": [
    "### Walkthrough\n",
    "\n",
    "I will walk you through an example of using the specified code that will automatically grab parquet files with the unique number identifier of 00000 through 00004. NOTE: the 'endfix' variable is for the 12/6/2024 update. It is very likely to be different once you run this package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a19c11-c25b-459e-b5a2-aee52c5c654e",
   "metadata": {},
   "source": [
    "As of the 12/6/2024 download, you can go to the following page to see all of the parquet files:\n",
    "\n",
    "https://source.coop/wherobots/usa-structures\n",
    "\n",
    "To the right of the .parquet files will show the size of them.\n",
    "Click on one of the .parquet file links, it should bring you to a window that details the file, for instance:\n",
    "\n",
    "#### File Name\n",
    "\n",
    "part-00000-170892fe-0fe0-43c1-999d-f0911ce43365-c000.zstd.parquet\n",
    "\n",
    "#### File Size\n",
    "\n",
    "2,058,402,104 Bytes (1.9 GiB)\n",
    "\n",
    "#### Content Type\n",
    "\n",
    "application/octet-stream\n",
    "\n",
    "#### Last Modified\n",
    "\n",
    "Fri Dec 06 2024 15:29:54 GMT-0500 (Eastern Standard Time)\n",
    "\n",
    "#### Data URL\n",
    "\n",
    "https://data.source.coop/wherobots/usa-structures/geoparquet/part-00000-170892fe-0fe0-43c1-999d-f0911ce43365-c000.zstd.parquet\n",
    "\n",
    "#### S3 URI\n",
    "\n",
    "s3://wherobots/usa-structures/geoparquet/part-00000-170892fe-0fe0-43c1-999d-f0911ce43365-c000.zstd.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29efb19b-3e40-47ee-a4a5-d7fd108aa0d1",
   "metadata": {},
   "source": [
    "# We are using an S3 client approach.\n",
    "### Therefore, focus on the S3 URI, this is what we use to download the data\n",
    "\n",
    "The bucket_name is 'whereobots'\n",
    "\n",
    "The prefix is everything after the bucket_name AND it's slash (/),  and everything before the unique #-identifier, 00000.\n",
    "\n",
    "The endfix is everything after the unique #-identifier, including the hyphen.\n",
    "\n",
    "#### Copy and paste any adjustments to the file link that have occurred since this update. It is very likely the bucket_name and prefix will be the same.\n",
    "\n",
    "#### In the code cell below, if you wish to automatically grab 'x' number of files, change the 'range(0, 5)' portion. This goes in numeric order:\n",
    "\n",
    "00000, 00001, 00002, 00003, 00004\n",
    "\n",
    "#### You can adjust the starting number to be something besides 0, and whichever number you want to end on, remember it is NOT inclusive. To go from 0-4, you must use 5 as the end number for the range function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec1c158a-46df-4661-af92-2a2614214cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['usa-structures/geoparquet/part-00000-170892fe-0fe0-43c1-999d-f0911ce43365-c000.zstd.parquet',\n",
       " 'usa-structures/geoparquet/part-00001-170892fe-0fe0-43c1-999d-f0911ce43365-c000.zstd.parquet',\n",
       " 'usa-structures/geoparquet/part-00002-170892fe-0fe0-43c1-999d-f0911ce43365-c000.zstd.parquet',\n",
       " 'usa-structures/geoparquet/part-00003-170892fe-0fe0-43c1-999d-f0911ce43365-c000.zstd.parquet',\n",
       " 'usa-structures/geoparquet/part-00004-170892fe-0fe0-43c1-999d-f0911ce43365-c000.zstd.parquet']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_name = 'wherobots'  # (Bucket name is the account the posted the dataset)?\n",
    "prefix = \"usa-structures/geoparquet/part-\"\n",
    "\n",
    "endfix = \"-170892fe-0fe0-43c1-999d-f0911ce43365-c000.zstd.parquet\"\n",
    "\n",
    "links = [f\"{prefix}{str(i).zfill(5)}{endfix}\" for i in range(0, 5)] # originally 0-200, datset updated mid project, now goes to 00009\n",
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a3250e-cc7d-4742-911c-6d399914c9e5",
   "metadata": {},
   "source": [
    "Going back to the beginning, you can specify if you'd prefer only 1 of the links:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08dafeff-ad2c-4119-bf8e-18882cb774d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['usa-structures/geoparquet/part-00000-170892fe-0fe0-43c1-999d-f0911ce43365-c000.zstd.parquet']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_link = links[0:1]\n",
    "one_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1f37cc-dc95-4c98-84ef-bee0be13ddf3",
   "metadata": {},
   "source": [
    "Or use the entire list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdb1d4ac-0ad0-41da-b3b5-2c754e974dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['usa-structures/geoparquet/part-00000-170892fe-0fe0-43c1-999d-f0911ce43365-c000.zstd.parquet',\n",
       " 'usa-structures/geoparquet/part-00001-170892fe-0fe0-43c1-999d-f0911ce43365-c000.zstd.parquet',\n",
       " 'usa-structures/geoparquet/part-00002-170892fe-0fe0-43c1-999d-f0911ce43365-c000.zstd.parquet',\n",
       " 'usa-structures/geoparquet/part-00003-170892fe-0fe0-43c1-999d-f0911ce43365-c000.zstd.parquet',\n",
       " 'usa-structures/geoparquet/part-00004-170892fe-0fe0-43c1-999d-f0911ce43365-c000.zstd.parquet']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_list = links\n",
    "link_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de32cb1-9539-41d9-bdca-d39124e90bdf",
   "metadata": {},
   "source": [
    "Finally, we will create the dask dataframe with your desired links. Now you may start analysis. Use code from 'worcester_analysis' as an example, but remember the warning from the README.md file. If you are trying to do a specific location, you will likely need to test several parquet files before you find it. AND there could be a situation where 2 or more parquet files cover your desired area. Proceed with caution as this could be the start of a LONG testing process. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd1ec936-ca68-4a2b-9beb-6ca04d76ad6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists locally. No download needed.\n",
      "File already exists locally. No download needed.\n",
      "File already exists locally. No download needed.\n",
      "File already exists locally. No download needed.\n",
      "File already exists locally. No download needed.\n"
     ]
    }
   ],
   "source": [
    "structure_ddf = ut.get_US_structures_specified(bucket_name, link_list, s3_client, local_path, blocksize = \"16M\")\n",
    "\n",
    "# This will use 'link_list'. If you desire to use the 'one_link', switch it out in the above function.\n",
    "\n",
    "# A note about the function: blocksize will vary by computers, 256MiB is a regular block size, my computer cannot handle that and uses 16M (M = MiB).\n",
    "# The blocksize helps handle large datasets.\n",
    "\n",
    "# More details can be found here: https://coderzcolumn.com/tutorials/python/dask-dataframes-guide-to-work-with-large-tabular-datasets\n",
    "# Use ctrl + f for 'blocksize'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01b4e1a-6574-4271-b505-93d021cf9ebf",
   "metadata": {},
   "source": [
    "##### If you download the data in your mounted folder, then each time you run the function it will produce the above output. Confirming you already have the data installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "531b9a92-ff19-454b-9f67-109878c77d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>BUILD_ID</th>\n",
       "      <th>OCC_CLS</th>\n",
       "      <th>PRIM_OCC</th>\n",
       "      <th>SEC_OCC</th>\n",
       "      <th>PROP_ADDR</th>\n",
       "      <th>PROP_CITY</th>\n",
       "      <th>PROP_ST</th>\n",
       "      <th>PROP_ZIP</th>\n",
       "      <th>OUTBLDG</th>\n",
       "      <th>...</th>\n",
       "      <th>USNG</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>IMAGE_NAME</th>\n",
       "      <th>IMAGE_DATE</th>\n",
       "      <th>VAL_METHOD</th>\n",
       "      <th>REMARKS</th>\n",
       "      <th>UUID</th>\n",
       "      <th>bbox</th>\n",
       "      <th>geohash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MULTIPOLYGON (((-170.8292 -14.32645, -170.8292...</td>\n",
       "      <td>12059</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>02L NK 18412 16164</td>\n",
       "      <td>-170.829258</td>\n",
       "      <td>-14.326434</td>\n",
       "      <td>104001005B4C3F00</td>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>Automated</td>\n",
       "      <td>None</td>\n",
       "      <td>{245aca01-8d02-4340-810e-3872ee35e7ef}</td>\n",
       "      <td>{'xmin': -170.82931163799998, 'ymin': -14.3264...</td>\n",
       "      <td>2jqw2xvymz0vch1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MULTIPOLYGON (((-170.82798 -14.32867, -170.827...</td>\n",
       "      <td>29894</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>02L NK 18540 15909</td>\n",
       "      <td>-170.828069</td>\n",
       "      <td>-14.328742</td>\n",
       "      <td>NOAA Topographic LiDAR</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>Unverified</td>\n",
       "      <td>None</td>\n",
       "      <td>{a46fac03-1829-47a2-b63f-86d4e52700a8}</td>\n",
       "      <td>{'xmin': -170.82815531799997, 'ymin': -14.3288...</td>\n",
       "      <td>2jqw2xwc12zkvd0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MULTIPOLYGON (((-170.82786 -14.3283, -170.8278...</td>\n",
       "      <td>29886</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>02L NK 18569 15948</td>\n",
       "      <td>-170.827797</td>\n",
       "      <td>-14.328382</td>\n",
       "      <td>NOAA Topographic LiDAR</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>Unverified</td>\n",
       "      <td>None</td>\n",
       "      <td>{4c8bb4a4-86e1-4cb2-908c-a367e7dfa525}</td>\n",
       "      <td>{'xmin': -170.82790860099996, 'ymin': -14.3284...</td>\n",
       "      <td>2jqw2xwgpg8y3ej</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MULTIPOLYGON (((-170.82747 -14.32844, -170.827...</td>\n",
       "      <td>29879</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>02L NK 18594 15936</td>\n",
       "      <td>-170.827566</td>\n",
       "      <td>-14.328497</td>\n",
       "      <td>NOAA Topographic LiDAR</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>Unverified</td>\n",
       "      <td>None</td>\n",
       "      <td>{22106c1f-562e-4468-a496-32d407fd8b4f}</td>\n",
       "      <td>{'xmin': -170.82767668499997, 'ymin': -14.3286...</td>\n",
       "      <td>2jqw2xx4mn23x0c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MULTIPOLYGON (((-170.82714 -14.32846, -170.827...</td>\n",
       "      <td>29885</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>02L NK 18636 15935</td>\n",
       "      <td>-170.827176</td>\n",
       "      <td>-14.328503</td>\n",
       "      <td>NOAA Topographic LiDAR</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>Unverified</td>\n",
       "      <td>None</td>\n",
       "      <td>{bc01e591-8516-49bf-b66e-dd21667de2f7}</td>\n",
       "      <td>{'xmin': -170.82721784799998, 'ymin': -14.3285...</td>\n",
       "      <td>2jqw2xx6qm2znys</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            geometry  BUILD_ID       OCC_CLS  \\\n",
       "0  MULTIPOLYGON (((-170.8292 -14.32645, -170.8292...     12059  Unclassified   \n",
       "1  MULTIPOLYGON (((-170.82798 -14.32867, -170.827...     29894  Unclassified   \n",
       "2  MULTIPOLYGON (((-170.82786 -14.3283, -170.8278...     29886  Unclassified   \n",
       "3  MULTIPOLYGON (((-170.82747 -14.32844, -170.827...     29879  Unclassified   \n",
       "4  MULTIPOLYGON (((-170.82714 -14.32846, -170.827...     29885  Unclassified   \n",
       "\n",
       "       PRIM_OCC SEC_OCC PROP_ADDR PROP_CITY         PROP_ST PROP_ZIP OUTBLDG  \\\n",
       "0  Unclassified    None      None      None  American Samoa     None    None   \n",
       "1  Unclassified    None      None      None  American Samoa     None    None   \n",
       "2  Unclassified    None      None      None  American Samoa     None    None   \n",
       "3  Unclassified    None      None      None  American Samoa     None    None   \n",
       "4  Unclassified    None      None      None  American Samoa     None    None   \n",
       "\n",
       "   ...                USNG   LONGITUDE   LATITUDE              IMAGE_NAME  \\\n",
       "0  ...  02L NK 18412 16164 -170.829258 -14.326434        104001005B4C3F00   \n",
       "1  ...  02L NK 18540 15909 -170.828069 -14.328742  NOAA Topographic LiDAR   \n",
       "2  ...  02L NK 18569 15948 -170.827797 -14.328382  NOAA Topographic LiDAR   \n",
       "3  ...  02L NK 18594 15936 -170.827566 -14.328497  NOAA Topographic LiDAR   \n",
       "4  ...  02L NK 18636 15935 -170.827176 -14.328503  NOAA Topographic LiDAR   \n",
       "\n",
       "   IMAGE_DATE  VAL_METHOD REMARKS                                    UUID  \\\n",
       "0  2020-05-14   Automated    None  {245aca01-8d02-4340-810e-3872ee35e7ef}   \n",
       "1  2013-01-01  Unverified    None  {a46fac03-1829-47a2-b63f-86d4e52700a8}   \n",
       "2  2013-01-01  Unverified    None  {4c8bb4a4-86e1-4cb2-908c-a367e7dfa525}   \n",
       "3  2013-01-01  Unverified    None  {22106c1f-562e-4468-a496-32d407fd8b4f}   \n",
       "4  2013-01-01  Unverified    None  {bc01e591-8516-49bf-b66e-dd21667de2f7}   \n",
       "\n",
       "                                                bbox          geohash  \n",
       "0  {'xmin': -170.82931163799998, 'ymin': -14.3264...  2jqw2xvymz0vch1  \n",
       "1  {'xmin': -170.82815531799997, 'ymin': -14.3288...  2jqw2xwc12zkvd0  \n",
       "2  {'xmin': -170.82790860099996, 'ymin': -14.3284...  2jqw2xwgpg8y3ej  \n",
       "3  {'xmin': -170.82767668499997, 'ymin': -14.3286...  2jqw2xx4mn23x0c  \n",
       "4  {'xmin': -170.82721784799998, 'ymin': -14.3285...  2jqw2xx6qm2znys  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure_ddf.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
